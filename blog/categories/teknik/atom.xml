<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Teknik | Aydın Doyak]]></title>
  <link href="http://aydintd.me/blog/categories/teknik/atom.xml" rel="self"/>
  <link href="http://aydintd.me/"/>
  <updated>2014-02-22T01:28:17+02:00</updated>
  <id>http://aydintd.me/</id>
  <author>
    <name><![CDATA[Aydın Doyak]]></name>
    <email><![CDATA[aydintd@bil.omu.edu.tr]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Docker ile mini-Heroku : Dokku Rehberi]]></title>
    <link href="http://aydintd.me/blog/2014/02/21/docker-ile-mini-heroku-dokku-rehberi/"/>
    <updated>2014-02-21T23:17:00+02:00</updated>
    <id>http://aydintd.me/blog/2014/02/21/docker-ile-mini-heroku-dokku-rehberi</id>
    <content type="html"><![CDATA[<p>Dokku, Docker ile geliştirilmiş, 100 satır civarında Bash koduyla provision edilen bir mini-Heroku, teknik adıyla PaaS projesidir.
Kısaca bir sunucu makine üzerinde Dokku habitatını sağladıktan sonra, Heroku uyumlu uygulamaları &ldquo;git&rdquo; yardımıyla sunucuya &ldquo;push&rdquo; ettiğiniz
esnek bir yapıyı kullanıma sunar. Pushladığınız uygulama, içeride Heroku Buildpack'lerini kullanarak kurulur ve
birbirinden izole Docker konteynırları içerisinde yaşamaya başlarlar. Sonuç olarak; size özel, tek merkezli bir Heroku'ya sahip olursunuz.</p>

<p>Dokku'nun tabiri yerindeyse hamal işini yapan 3 ağır işçisi var : Docker, Buildstep ve sshcommand(gitreceive)</p>

<ul>
<li><p><a href="http://docker.io/" title="Docker">Docker</a> : Linux ortamlarında, hafif, güçlü, kendi kendine yeten konteynırlar oluşturmaya yarayan
açık kaynaklı bir projedir. Geliştiricilerin uygulamalarını laptoplarında, bare metal sunucularda, ürün makinelerinde,
bulut sistemlerde, hatta sanal makinelerde dahi hızla test edebilmeleri, ürün servis edebilmelerine
olanak sağlayan bir &ldquo;container runtime&rdquo; projesidir.</p></li>
<li><p><a href="https://github.com/progrium/buildstep" title="Buildstep">Buildstep</a> : Heroku'nun açık kaynaklı &ldquo;buildpack"lerini; uygulamaların,
üzerine kurulacağı temel imajı inşa etmek amacıyla kullanan bir inşaat aracıdır. Projenin adının "Docker + Heroku = Dokku&rdquo; olmasının sebebi aslında buradan kaynaklı.</p></li>
<li><p><a href="https://github.com/progrium/sshcommand" title="Sshcommand">Sshcommand</a> : Heroku'dan aşina olduğumuz &ldquo;push&rdquo; mekanizmasını Dokku'ya kazandıran bir projedir.Size bir &ldquo;git&rdquo; kullanıcısı sağlayıp, bu kullanıcı üzerinden Dokku'ya depo push etmenize olanak sağlar.</p></li>
</ul>


<p>Gel gelelim hikayeden sonra işin zevkli kısmına.</p>

<h2>Dokku Kurulumu</h2>

<p>Ben bu rehberde kendi yerelinizde Dokku'yla nasıl oynayabileceğinizi anlatacağımdan dolayı deponun içerisinde hazır gelen Vagrant makinesi yoluyla kurulum yolunu izleyeceğim.</p>

<p>Dokku'nun Vagrant makinesi Ubuntu 13.04 Raring Ringtail sürümü ile geliyor. Dokku kurulumunu sanal bir makinede yapacaksanız, Ubuntu 13 serisi işletim sistemi olarak tavsiye ediliyor.</p>

<p>Ben bu rehberde <a href="https://github.com/progrium/dokku" title="Dokku">Dokku</a>&lsquo;nun kurulumu ve daha önceden Node.js ile hazırlanmış bir &ldquo;Hello World!&rdquo; uygulamasının Dokku'ya nasıl push edileceğini anlatacağım.</p>

<!-- more -->


<h3>Geliştirme Ortamının Sağlanması</h3>

<p>Geliştirme ortamını hazırlarken, Dokku'yu Vagrant makinesi yardımıyla kuracağımdan, çalıştığınız host makinede &ldquo;vagrant, buna bağlı olarak
virtualbox ve git&rdquo; kurulu olduğundan emin olun. Aksi halde kurulumu takip edemezsiniz.</p>

<h3>Dokku klonlanması ve Yerel Ağ Ayarları</h3>

<p>Çalışma ortamınıza Dokku'yu klonlayın :</p>

<p><code>$ git clone git@github.com:progrium/dokku.git</code></p>

<p><code>$ cd dokku</code></p>

<p>Gördüğünüz üzere Dokku deposu halihazırda bir Vagrantfile ile gereken tüm ayarlarla beraber geliyor.</p>

<p>İçeriğine göz atacak olursak :</p>

<pre><code>BOX_NAME = ENV["BOX_NAME"] || "raring"
BOX_URI = ENV["BOX_URI"] || "https://cloud-images.ubuntu.com/vagrant/raring/current/raring-server-cloudimg-amd64-vagrant-disk1.box"
BOX_MEMORY = ENV["BOX_MEMORY"] || "512"
DOKKU_DOMAIN = ENV["DOKKU_DOMAIN"] || "dokku.me"
DOKKU_IP = ENV["DOKKU_IP"] || "10.0.0.2"
PREBUILT_STACK_URL = File.exist?("#{File.dirname(__FILE__)}/stack.tgz") ? 'file:///root/dokku/stack.tgz' : nil

make_cmd = "make install"
if PREBUILT_STACK_URL
  make_cmd = "PREBUILT_STACK_URL='#{PREBUILT_STACK_URL}' #{make_cmd}"
end
...
..
</code></pre>

<p>Dokku'nun Ubuntu sunucularından raring imajı temel kutu olarak indirilip, &ldquo;dokku.me&rdquo; domain adıyla 10.0.0.2 sanal ip'sinde çalışacak şekilde ayarlanmış
olduğunu görüyoruz. Dilerseniz domain adını, makine'nin ip'sini dilediğiniz şekilde değiştirebilirsiniz. Ben tembellik edip bu şekilde bırakacağım.
Değişiklik yaparsanız aşağıda anlatılanlar üzerinde değişikliklerinizi yapmayı da unutmayın.</p>

<p>Vagrantfile'da tanımlı bilgilere göre, Dokku çalıştığında makineye ulaşabilmeniz için yerelinizde aşağıdaki değişiklikleri yapmanız gerekiyor :</p>

<p><code>$ vim /etc/hosts</code></p>

<pre><code>...
..
10.0.0.2 dokku.me
10.0.0.2 node-js-sample.dokku.me
</code></pre>

<p>Bu satırları hosts tanımı olarak girdiğinizde, yerel makinenizden sanal Dokku sunucunuza erişebilir olacaksınız.
İkinci satırı, Dokku'ya push edilen uygulamaya ulaşabilmek için giriyoruz. Tamamen DNS olayı.</p>

<h3>Kutu Ateşleme</h3>

<p>Son olarak, dokku dizini içerisinde vagrant makinesini ayağa kaldırıyoruz :</p>

<p><code>$ vagrant up</code></p>

<pre><code>Bringing machine 'default' up with 'virtualbox' provider...
[default] Importing base box 'raring'...
[default] Matching MAC address for NAT networking...
[default] Setting the name of the VM...
[default] Clearing any previously set forwarded ports...
[default] Clearing any previously set network interfaces...
[default] Preparing network interfaces based on configuration...
[default] Forwarding ports...
[default] -- 22 =&gt; 2222 (adapter 1)
[default] -- 80 =&gt; 8080 (adapter 1)
[default] Running 'pre-boot' VM customizations...
[default] Booting VM...
[default] Waiting for machine to boot. This may take a few minutes...
[default] Machine booted and ready!
[default] Setting hostname...
[default] Configuring and enabling network interfaces...
[default] Mounting shared folders...
[default] -- /vagrant
[default] -- /root/dokku
[default] Running provisioner: shell...
[default] Running: inline script
Reading package lists...
Building dependency tree...
Reading state information...
...
</code></pre>

<p>Burada önemli olan, makine boot olduktan sonra Dokku ortamının bash betikleriyle provision ediliyor olması. Makine kurulumu bittikten sonra, makinenin içerisinde docker, buildpack ve sshcommand kurulumları yapılmış ve Dokku habitatı kullanıma hazır hale gelmiş olacak.</p>

<p>Kurulum sonunda makineye ssh'la bağlanabiliyor olmalısınız :</p>

<p><code>$ vagrant ssh</code></p>

<p>Makine içerisine girdikten sonra aşağıdaki komutu vererek makinenin doğru şekilde hazırlandığından emin olun :</p>

<pre><code>$ docker --version 
&gt; Docker version 0.8.1, build a1598d1
</code></pre>

<p>Eğer makineye bağlanamıyorsanız, kutu ayakta değil demektir. Aşağıdaki komutla kutuyu yeniden up etmeyi deneyin :</p>

<p><code>$ vagrant reload</code></p>

<p>Makineye bağlanabiliyor ancak docker gibi gerekli programların makineye kurulmadığını düşünüyorsanız :</p>

<p><code>$ vagrant provision</code></p>

<p>Eğer hiç bir sıkıntı yoksa, tebrikler mini minnacık bir Heroku'nuz meydana geldi :&ndash;)</p>

<h2>Dokku'ya Uygulama Konuşlandırma</h2>

<p>Rehberin ikinci ayağı, ektiğinizi biçeceğiniz bölüm burası.</p>

<p>Dokku'ya uygulama konuşlandırabilmeniz için, kullanıcınızın RSA açık anahtarının Dokku'ya bildirilmesi gerekiyor.
Böylece Dokku sizi tanıyacak ve sizden gelen depoları konteynırlara yerleştirecek.</p>

<p>Aşağıdaki komutu yerelinizde verin :</p>

<p><code>$ cat ~/.ssh/id_rsa.pub | ssh vagrant@dokku.me "sudo sshcommand acl-add dokku &lt;aydintd&gt;</code></p>

<p>Parola istediğinde, öntanımlı &lsquo;vagrant&rsquo; parolasını girin. aydintd yerine kendi kullanıcınızın ismini yazın.</p>

<p>Dokku'ya parola aracılığıyla erişmeye çalışırken :</p>

<pre><code>Permission denied (publickey)
</code></pre>

<p>gibi bir hata alabilirsiniz. Bu vagrant kutusuyla alakalı bir bug, elle düzeltmek gerekiyor :</p>

<p>Dokku sunucusuna bağlanıp, aşağıdaki adımları takip edin :</p>

<pre><code>$ sudo vim /etc/ssh/sshd_config

PasswordAuthentication yes   &lt;bu girdiyi yes olarak değiştirin&gt;

$ sudo service ssh restart
</code></pre>

<p>Makineden çıkıp açık anahtarınızı sunucuya tekrar göndermeyi deneyin.</p>

<p>Şu şekilde bir çıktı görüyorsanız başarıyla anahtarınızı sunucuya gönderdiniz demektir :</p>

<pre><code>$ cat ~/.ssh/id_rsa.pub | ssh root@dokku.me "sudo sshcommand acl-add dokku aydintd"
root@dokku.me's password: 
xx:3x:x6:xf:xe:f3:xx:xx:xx:xx:aa:cc:12:34:56:71
</code></pre>

<p>Son olarak <a href="http://github.com/heroku/node-js-sample" title="Buradaki">Buradaki</a> Node.js uygulamasını Dokku'ya konuşlandıralım :</p>

<p>Linkteki depoyu yerelinize klonladıktan sonra, aşağıdaki adımları takip edin :</p>

<p><code>$ cd node-js-sample</code></p>

<p><code>$ git remote add aydintd dokku@dokku.me:node-js-sample</code></p>

<p><code>$ git push aydintd master</code></p>

<p>Böylece uygulamanızı Dokku'ya push ediyorsunuz. Çıktıların en sonuna bakacak olursanız :</p>

<pre><code>-----&gt; Building runtime environment
-----&gt; Discovering process types
    Procfile declares types -&gt; web
-----&gt; Releasing node-js-sample ...
-----&gt; Deploying node-js-sample ...
=====&gt; Application deployed:
    http://node-js-sample.dokku.me

To dokku@dokku.me:node-js-sample
[new branch]      master -&gt; master
</code></pre>

<p><a href="http://node-js-sample.dokku.me">http://node-js-sample.dokku.me</a> adresini tarayıcınızda görüntülediğinizde Hello World! yazısını görüyorsanız başarıyla uygulamanızı Dokku'da konuşlandırdınız demektir.</p>

<h2>Dokku Dünyasına Merhaba Diyemediyseniz  :</h2>

<p>Herşeyden önce Dokku'ya bağlanıp, uygulamanızın varlığını kontrol edin :</p>

<p><code>$ sudo docker ps</code></p>

<pre><code>CONTAINER ID        IMAGE                       COMMAND                CREATED             STATUS              PORTS                     NAMES
01510b674a70        app/node-js-sample:latest   /bin/bash -c /start    6 minutes ago       Up 6 minutes        0.0.0.0:49153-&gt;5000/tcp   thirsty_euclid
</code></pre>

<p>Yukarıdaki gibi bir girdi görüyorsanız, uygulamanız konteynır hale getirilmiş demektir. Eğer bu girdiyi görüyor ancak tarayıcınızda Hello World! yazısıgöremiyorsanız tarayıcınıza <code>dokku.me:49153</code> yazmayı deneyin. Eğer bu şekilde görüntüleyebiliyorsanız, uygulamanızın nginx ayarları doğru çalışmıyor diyebilirsiniz.</p>

<p>Dokku'da her uygulama <code>/home/dokku/project-name</code> olarak konuşlanır. Bu dizin içerisindeki ayarlarla oynayarak debugging yapabilirsiniz.</p>

<p>Hepsi bu kadar :&ndash;)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logical Volume Manager (LVM) Rehberi]]></title>
    <link href="http://aydintd.me/blog/2013/08/25/logical-volume-manager-lvm-rehberi/"/>
    <updated>2013-08-25T16:38:00+03:00</updated>
    <id>http://aydintd.me/blog/2013/08/25/logical-volume-manager-lvm-rehberi</id>
    <content type="html"><![CDATA[<p>LVM yani Logical Volume Manager var olan fiziksel diskleri, insanlık tarihinden bu yana gelen &ldquo;böl, parçala, yönet&rdquo;
mantığıyla sanallaştırıp yönetmek amaçlı yazılmış çok yararlı bir program. Bir ya da birden fazla olan disklerinizi
tek bir disk havuzuymuş gibi gösterip, partitions ile karmaşık disk alanı hesaplamalarını sizin yerinize soyutlayıp
yapıyor.</p>

<p>Bir çok linux dağıtımı artık öntanımlı LVM disk formatı seçeneğiyle gelmekte. Özellikle son sürüm işletim sistemleri
aksini belirtmediğiniz takdirde bu şekilde sisteminize kuruluyor.</p>

<p>Bu blog yazısında lvm ile volume grup oluşturma, birden fazla olan disklerinizi volume gruplar
içerisinde toplayıp daha sonrasında toplam disk alanınız üzerinden nasıl disk bölümlemesi yapıldığını anlatacağım.</p>

<h2>Hazırlık</h2>

<p>Ben bir Ubuntu 12.10 sanal makinesi üzerinde 16GB ve 14GB lık iki diski lvm ile sanallaştırıp toplamda 30GB lık tek bir
sanal disk yaratıp, daha sonra keyfimize göre bu diski sanal olarak bölümleyeceğim.</p>

<p>Aşağıdaki komut ile disklerinizi görüntüleyin.</p>

<p><code>$ sudo fdisk -l</code></p>

<p>Aşağıdaki gibi bölümler göreceksiniz :</p>

<pre><code>`Disk /dev/sdb: 17.2 GB, 17179869184 bytes
255 heads, 63 sectors/track, 2088 cylinders, total 33554432 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/sdb doesn't contain a valid partition table

Disk /dev/sdc: 15.0 GB, 15032385536 bytes
255 heads, 63 sectors/track, 1827 cylinders, total 29360128 sectors
Units = sectors of 1 * 512 = 512 bytes
Sector size (logical/physical): 512 bytes / 512 bytes
I/O size (minimum/optimal): 512 bytes / 512 bytes
Disk identifier: 0x00000000

Disk /dev/sdc doesn't contain a valid partition table`
</code></pre>

<p>Bu çıktıdan anladığımız, işletim sistemimiz disklerimizden fiziksel olarak haberdar, ancak
hiç bir disk bölümlemesi yapılmadığından dolayı ağlıyor.</p>

<p>Disk bölümlemelerini aşağıdaki gibi yapın :</p>

<p><code>$ sudo fdisk /dev/sdb</code></p>

<p>Açılan konsolda <code>m</code> harfine basarak aşağıdaki gibi yardımcı komutu görüntüleyebilirsiniz :</p>

<pre><code>Command action
    a   toggle a bootable flag
    b   edit bsd disklabel
    c   toggle the dos compatibility flag
    d   delete a partition
    l   list known partition types
    m   print this menu
    n   add a new partition
    o   create a new empty DOS partition table
    p   print the partition table
    q   quit without saving changes
    s   create a new empty Sun disklabel
    t   change a partition's system id
    u   change display/entry units
    v   verify the partition table
    w   write table to disk and exit
    x   extra functionality (experts only)
</code></pre>

<p><code>n</code> harfiyle <code>/dev/sdb</code> diskinde bir bölüm oluşturma işine başlayın. Size bu bölümün primary mi logical mı olacağını soracak.
Öntanımlı primary olarak seçim geliyor. Primary seçtikten sonra oluşturduğumuz disk bölümü için 1-4 arası bir değer girmenizi
sizden isteyecek. İsteğinize göre seçip disk bölümünün diskin ne kadarını bölüm için ayarlayacağınızı size soracak. Ben bu örnekte
tüm diski tek bir bölüm olarak oluşturacağım. Daha sonra <code>w</code> harfiyle değişiklikleri yapıp fdisk programından çıkış yapacağım.</p>

<p>Yukarıda anlatmaya çalıştığım süreç aşağıdaki gibi gözükecek :</p>

<pre><code>Command (m for help): n
Partition type:
    p   primary (0 primary, 0 extended, 4 free)
    e   extended
    Select (default p): 
    Using default response p
    Partition number (1-4, default 1): 
    Using default value 1
    First sector (2048-33554431, default 2048): 
    Using default value 2048
    last sector, +sectors or +size{K,M,G} (2048-33554431, default 33554431): 
    Using default value 33554431

    Command (m for help): w
    The partition table has been altered!

    Calling ioctl() to re-read partition table.
    Syncing disks.

vagrant@precise32:~$
</code></pre>

<p>Aynı işlemi <code>/dev/sdc</code> için de yapın.</p>

<!--more-->


<h2>LVM Rehberi</h2>

<p>Şu anda sistemimizdeki 16GB ve 14GB lık iki diskimizi oluşturduk. Sıra bu diskleri <code>lvm</code> ile sanallaştırmaya geldi.</p>

<p><code>lvm2</code> programını aşağıdaki şekilde indirin :</p>

<p><code>$ sudo apt-get install lvm2</code></p>

<p>Eklediğimiz diskleri physical volume olarak oluşturmamız gerekecek :</p>

<p><code>$ sudo pvcreate /dev/sdb1 /dev/sdc1</code></p>

<p>Physical volume disklerinizi listeleyin :</p>

<p><code>$ sudo pvs</code></p>

<pre><code>vagrant@precise32:~$ sudo pvs
    PV         VG        Fmt  Attr PSize  PFree 
    /dev/sda5  precise32 lvm2 a-   79.76g     0 
    /dev/sdb1            lvm2 a-   16.00g 16.00g
    /dev/sdc1            lvm2 a-   14.00g 14.00g
</code></pre>

<p>Detaylı liste için :</p>

<p><code>$ sudo pvdisplay</code></p>

<p>Physical Volume'lerinizin herhangi bir Volume Grubuna ait olmadığı yukarıda gözüküyor. Sıra geldi bu iki diskimizi
<code>vg1</code> isimli bir volume grup içine alıp, iki ayrı fiziksel diskimizi tek bir diskmiş gibi sanallaştıralım :</p>

<p><code>$ sudo vgcreate vg1 /dev/sdb1 /dev/sdc1</code></p>

<p>Volume Group listelemek için :</p>

<p><code>$ sudo vgdisplay</code></p>

<p>Çıktısını aşağıdaki gibi :</p>

<pre><code>vagrant@precise32:~$ sudo vgdisplay 
--- Volume group ---
VG Name               vg1
  System ID             
    Format                lvm2
    Metadata Areas        2
    Metadata Sequence No  1
    VG Access             read/write
    VG Status             resizable
    MAX LV                0
    Cur LV                0
    Open LV               0
    Max PV                0
    Cur PV                2
    Act PV                2
    VG Size               29.99 GiB
    PE Size               4.00 MiB
    Total PE              7678
    Alloc PE / Size       0 / 0   
    Free  PE / Size       7678 / 29.99 GiB
    VG UUID               K9QzS7-D8aI-O24O-Rcsb-2aMd-pY2D-3zjP5w
</code></pre>

<p>Yukarıda görebileceğiniz gibi 2 metadata alanı (2 disk) ve toplamda 29.99 GiB tek bir sanal disk oluşturduk.</p>

<p>Şimdi sıra oluşturduğumuz vg1 isimli Volume Group'u istediğimiz büyüklükte istediğimiz kadar sanal diske bölüp
sistemimizde kullanılabilir hale getirmeye geldi.</p>

<p>Ben örnek olarak 30 GiB lık toplam boş alanı olan diskimi <code>lv01</code> ve <code>lv02</code> 15 ve 14er GiB lık sanal disklere böleceğim.</p>

<p><code>NOT:</code> Tembel olduğumdan dolayı tam 30 GiB alan hesaplamaya üşendim açıkcası. :)</p>

<p><code>$ sudo lvcreate -L +15G -n lv01 vg1</code></p>

<p><code>sudo lvcreate -L +14G -n lv02 vg1</code></p>

<p>Şimdi oluşturduğumuz Logical Volume'larımızı listeleyelim :</p>

<p><code>$ sudo lvdisplay</code></p>

<pre><code>vagrant@precise32:~$ sudo lvdisplay 
--- Logical volume ---
LV Name                /dev/vg1/lv01
VG Name                vg1
LV UUID                W9TxNd-ORun-k0Cx-2psu-iI1p-8fQc-SroVSm
LV Write Access        read/write
LV Status              available
# open                 0
LV Size                15.00 GiB
Current LE             3840
Segments               1
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           252:2

--- Logical volume ---
LV Name                /dev/vg1/lv02
VG Name                vg1
LV UUID                zP1NJX-QwlD-JzBm-PYLU-5nFZ-i9vq-q7n3Vv
LV Write Access        read/write
LV Status              available
# open                 0
LV Size                14.00 GiB
Current LE             3584
Segments               2
Allocation             inherit
Read ahead sectors     auto
- currently set to     256
Block device           252:3
</code></pre>

<p>Logical Volume'larımızı da oluşturduk. Sıra geldi bunu sistemimizde kullanılabilir hale getirmeye :</p>

<p>Ubuntu ortamında geliştirme yaptığım için <code>mkfs</code> programı kullanarak oluşturduğum sanal diskleri <code>ext4</code> ile formatlayacağım :</p>

<p><code>$ sudo mkfs.ext4 /dev/mapper/vg1-lv02</code></p>

<p>Çıktısı aşağıdaki gibi olacak :</p>

<pre><code>vagrant@precise32:~$ sudo mkfs.ext4 /dev/vg1/lv01
mke2fs 1.42 (29-Nov-2011)
Filesystem label=
OS type: Linux
Block size=4096 (log=2)
Fragment size=4096 (log=2)
Stride=0 blocks, Stripe width=0 blocks
983040 inodes, 3932160 blocks
196608 blocks (5.00%) reserved for the super user
First data block=0
Maximum filesystem blocks=4026531840
120 block groups
32768 blocks per group, 32768 fragments per group
8192 inodes per group
Superblock backups stored on blocks: 
32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208

Allocating group tables: done
Writing inode tables: done
Creating journal (32768 blocks): done
Writing superblocks and filesystem accounting information: done 
</code></pre>

<p>Aynı işlemi oluşturduğumuz diğer Logical Volume için de yapıp diski formatlayın.</p>

<p>Artık <code>ext4</code> olarak formatladığımız 15 GB'lık diskimizi sistemde kullanabiliriz.</p>

<p>Ben <code>/mnt</code> dizini altında disk1 isimli bir dizin oluşturup, bu dizin altına <code>lv01</code> diskimi <code>mount</code> edeceğim.</p>

<p><code>$ sudo mkdir /mnt/disk1</code></p>

<p><code>$ sudo mount /dev/vg1/lv01 /mnt/disk1</code></p>

<p>Ve diskiniz hazır, diğer hazırladığınız diski de dilerseniz aynı yöntemle formatlayıp sisteme mount edebilirsiniz.</p>

<p>Diski görebilmek için :</p>

<p><code>$ df -h</code></p>

<pre><code>vagrant@precise32:/mnt/disk2$ df -h
Filesystem                  Size  Used Avail Use% Mounted on
/dev/mapper/precise32-root   79G  2.1G   73G   3% /
udev                        178M  4.0K  178M   1% /dev
tmpfs                        74M  296K   74M   1% /run
none                        5.0M     0  5.0M   0% /run/lock
none                        185M     0  185M   0% /run/shm
/dev/sda1                   228M   24M  192M  12% /boot
/vagrant                    290G   65G  225G  23% /vagrant
/dev/mapper/vg1-lv01         15G  354M   14G   3% /mnt/lv01
/dev/mapper/vg1-lv02         14G  340M   13G   3% /mnt/disk2
</code></pre>

<p>Hepsi bu kadar :)</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[RedHat Scientific Linux CentOS Sanal Makine Klonlarının eth0 Ağ Arayüzü Hatasının Düzeltilmesi]]></title>
    <link href="http://aydintd.me/blog/2013/06/25/redhat-scientific-linux-centos-sanal-makine-klonlanirken-eth0-ag-arayuzu-hatasinin-duzeltilmesi/"/>
    <updated>2013-06-25T02:25:00+03:00</updated>
    <id>http://aydintd.me/blog/2013/06/25/redhat-scientific-linux-centos-sanal-makine-klonlanirken-eth0-ag-arayuzu-hatasinin-duzeltilmesi</id>
    <content type="html"><![CDATA[<p>Scientific Linux 6 sürümünü VirtualBox'da &ldquo;bare&rdquo; olarak klonlayıp, ağ konfigürasyonunu
yaparken ilginç bir hatayla karşılaştım. İnternette bir çok yerde SL, CentOS ve
türev sürümlerinin VirtualBox klonlarının internet erişimini sağlayamadığından yakınan
baya bir kullanıcı girdisi okudum.<br/>
Bir kaç okuma yaptıktan sonra, şöyle bir şey keşfettim :</p>

<p>VirtualBox, VMWare gibi sanallaştırma araçları, ilgili klonların her birine
kendisi bir MAC adresi atıyor. Ancak SL, CentOS gibi sürümlerin kernel'leri kendilerine atanan
bu yeni konfigürasyonu ilk başta update edemiyorlar. Eski kernel'da kayıtlı MAC adresiyle
VBox'un klonlara atadığı MAC adresi de örtüşmediğinden sanal makineniz sadece loopback
arayüzünü başlatabiliyor ve eth0 ölü halde kalıyor. Dolayısıyla klonlar internete
çıkamıyorlar.</p>

<h2>Peki Çözüm Nasıl Olmalı?</h2>

<ul>
<li>Kernel'ın başta oluşturduğu &ldquo;ağ arayüzü kuralları&rdquo; dosyasını silelim. Böylece
klon yeniden başlatıldığında kernel kendine yeni bir kural dosyası üretebilsin
ve böylece VM tarafından atanan yeni MAC adresini kendine kaydedebilsin :</li>
</ul>


<p><code>$ sudo rm -rf /etc/udev/rules.d/70-persistent-net.rules</code></p>

<p><code>$ sudo reboot</code></p>

<ul>
<li>Makine yeniden başladıktan sonra sıra geldi ağ yapılandırmasına.
SL 6.4 de default olarak gelen text editörü <code>vi</code> olduğundan dosya
düzenlemelerini vi ile göstereceğim :</li>
</ul>


<p><code>$ sudo vi /etc/sysconfig/network-scripts/ifcfg-eth0</code></p>

<ul>
<li>Dosyada aşağıdaki değişiklikleri uygulayalım :</li>
</ul>


<p><code>MACADDR</code> girdisini kaldıralım.</p>

<p><code>UUID</code> girdisini kaldıralım.</p>

<p>ve dosyayı kaydedip çıkalım.</p>

<ul>
<li>Ağ konfigürasyonumuzu tamamladık, servisi yeniden başlatmalıyız ki girdiğimiz
ayarlar klon tarafından görülebilsin.</li>
</ul>


<p><code>$ service network restart</code></p>

<ul>
<li>ve İnternete çıkış yaptık mı? Ping'leyerek kontrol edelim :</li>
</ul>


<p><code>$ ping 8.8.8.8</code></p>

<p>Ta-daa! Klonunuz internete çıkmaya hazır. Tek yapmanız gereken ihtiyacınız olan servisi
&ldquo;yum"lamak.</p>

<p><code>Önemli Not:</code> VirtualBox'da Ağ Seçeneği NAT olarak ayarlı olmalı.</p>

<h2>Kaynakça</h2>

<p><code>http://blog.roozbehk.com/post/35156862882/redhat-add-network-eth</code></p>

<p><code>http://www.envision-systems.com.au/blog/2012/09/21/fix-eth0-network-interface-when-cloning-redhat-centos-or-scientific-virtual-machines-using-oracle-virtualbox-or-vmware/</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ubuntuda Java EE uygulamaları için Apache tomcat7 Uygulama Sunucusunun Kurulumu]]></title>
    <link href="http://aydintd.me/blog/2013/02/26/ubuntuda-java-ee-uygulamalar%C4%B1-i%C3%A7in-apache-tomcat7-uygulama-sunucusunun-kurulumu/"/>
    <updated>2013-02-26T23:34:00+02:00</updated>
    <id>http://aydintd.me/blog/2013/02/26/ubuntuda-java-ee-uygulamaları-için-apache-tomcat7-uygulama-sunucusunun-kurulumu</id>
    <content type="html"><![CDATA[<p>  Java2EE web uygulamaları için gereken açık kaynak apache-tomcat7 uygulama<br/>
  sunucusunun kurulumunu adım adım takip edelim :</p>

<h3>Başlarken</h3>

<p>  Kurulum Linux Ubuntu 12.10 32bit işletim sistemi üzerinde Apache Tomcat 7.0.30<br/>
  sürümü olarak sizi yönlendirecektir.</p>

<ul>
<li> Not : Tomcat Uygulama sunucusunu kurmadan, makinenizde Java nın kurulu<br/>
olduğundan emin olun.</li>
</ul>


<h3>Kurulum</h3>

<p>  Aşağıdaki komutları çalıştırın :</p>

<p>  <code>$ sudo apt-get update &amp;&amp; sudo apt-get install tomcat7</code></p>

<p>  Böylece tomcat7 uygulama sunucusunu makinemize kurmuş olacağız.</p>

<!--more-->


<h3>Konfigurasyon</h3>

<p>  tomcat7 sunucusunu konfigurasyona başlamak için durduralım :</p>

<p>  <code>$ sudo service tomcat7 stop</code></p>

<p>  <code>&gt; Stopping Tomcat servlet engine tomcat7 [ OK ]</code></p>

<p>  Favori text editörünüzle tomcat7 in ayar dosyasını açıp içerisindeki commentli halde bulunan (#)<br/>
  JAVA_HOME dosya yolununun commentini kaldırıp aşağıdaki hale getirin.</p>

<p>  <code>$ sudo vim /etc/default/tomcat7</code></p>

<p>  <code>JAVA_HOME=/usr/lib/jvm/jdk1.7.0</code></p>

<ul>
<li> Not : Makinenizde kurulu olan JDK nın dosya yolunu doğru verdiğinizden emin<br/>
olun. Aksi halde uygulama sunucunuz başlayamayacaktır.</li>
</ul>


<p>  Sunucumuzu tekrar başlatalım :</p>

<p>  <code>$ sudo service tomcat7 start</code></p>

<p>  Tomcat için Firewall unuzda ön tanımlı bir port açın :</p>

<p>  <code>$ sudo ufw enable 8080/tcp</code></p>

<p>  Sunucunun JDK üzerinde çalıştığından emin olalım :</p>

<p>  <code>$ /usr/share/tomcat7/bin/version.sh</code></p>

<p>  Aşağıdaki gibi JVM çıktılarını gözlemlemelisiniz.</p>

<pre><code>    Using CATALINA_BASE:   /usr/share/tomcat7     
    Using CATALINA_HOME:   /usr/share/tomcat7     
    Using CATALINA_TMPDIR: /usr/share/tomcat7/temp        
    Using JRE_HOME:        /usr       
    Using CLASSPATH:    
    /usr/share/tomcat7/bin/bootstrap.jar:/usr/share/tomcat7/bin/tomcat-juli.jar      
    Server version: Apache Tomcat/7.0.30        
    Server built:   Jan 10 2013 04:10:25        
    Server number:  7.0.30.0    
    OS Name:        Linux       
    OS Version:     3.5.0-25-generic    
    Architecture:   i386  
    JVM Version:    1.7.0-b147  
    JVM Vendor:     Oracle Corporation  
</code></pre>

<h3>Son</h3>

<p>  Web Browser a <code>http://localhost:8080</code> yazdığınızda <code>It Works!</code> gibi bir yazı  <br/>
  görüyorsanız, tomcat7 uygulama sunucu kurulumunu başarıyla gerçekleştirmişsinizdir.</p>

<ul>
<li>Önemli not : Kurulumdan hemen sonra Eclipse editörü üzerinde bir<br/>
Java EE uygulamasını görüntülemek istiyorsanız, tomcat7 sunucunuzu konsoldan tekrar kapatmanız gerekebilir.<br/>
Uygulamayı görüntülemeye çalıştığınızda tomcat7 in başka bir prosesle meşgul olduğu<br/>
mesajıyla karşı karşıya kalırsanız,tomcat7 sunucusunu elle kapatın ve Eclipse editörü yardımıyla
uygulamanızı tekrar sunucu üzerinde görüntülemeye çalışın.(çalıştırın)</li>
</ul>


<h3>Kaynakça</h3>

<p>  <code>http://hendrelouw73.wordpress.com</code><br/>
  <code>blog.eviac.com</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Vagrant 2]]></title>
    <link href="http://aydintd.me/blog/2013/02/22/vagrant-2/"/>
    <updated>2013-02-22T02:02:00+02:00</updated>
    <id>http://aydintd.me/blog/2013/02/22/vagrant-2</id>
    <content type="html"><![CDATA[<p>  Vagrant Temel Kutu Hazırlama konusunda hazırladığım doküman sayfasına
  aşağıdaki linkten ulaşabilirsiniz.</p>

<p>  <a href="http://aydintd.me/fo/vagrant-2/#slide1">Vagrant 2</a></p>
]]></content>
  </entry>
  
</feed>
